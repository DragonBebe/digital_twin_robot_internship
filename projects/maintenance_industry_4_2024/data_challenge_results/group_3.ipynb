{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":80701,"databundleVersionId":8704113,"sourceType":"competition"}],"dockerImageVersionId":30715,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Problem definition and task allocations.\n\nIn this section, please describe briefly:\n- the problems in this project.\nTesting different models and seeing performance for each, while seeing which one is best for fault detection at each individual motor.\n\n- how do you attribute the tasks to the team members.\n\n| Member | Task | \n| --- | --- |\n| Giovanni Low | Motor 1 |\n| Lara Szterensus | Motor 2 |\n| Beatriz Raposo | Motor 3 |\n| Merse Szalai | Motor 4 |\n| Juan Baserga | Motor 5 |\n| Juan Baserga | Motor 6 |\n\n","metadata":{}},{"cell_type":"code","source":"import sys\nimport numpy as np\nimport pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import RobustScaler, StandardScaler\nfrom sklearn.model_selection import GridSearchCV, StratifiedKFold\nimport warnings\n\n# Import custom utility function\npath_supporting_script = '/kaggle/input/robot-predictive-maintenance/'\nsys.path.insert(1, path_supporting_script)\nfrom utility import read_all_test_data_from_path, extract_selected_feature, prepare_sliding_window\n\nwarnings.filterwarnings('ignore')\n\n# Load Data\ndef load_data():\n    train_data_path = '/kaggle/input/robot-predictive-maintenance/training_data/training_data/'\n    test_data_path = '/kaggle/input/robot-predictive-maintenance/testing_data/testing_data/'\n    df_train = read_all_test_data_from_path(train_data_path, pre_processing, is_plot=False)\n    df_test = read_all_test_data_from_path(test_data_path, pre_processing, is_plot=False)\n    return df_train, df_test\n","metadata":{"execution":{"iopub.status.busy":"2024-06-04T22:02:54.509382Z","iopub.execute_input":"2024-06-04T22:02:54.509969Z","iopub.status.idle":"2024-06-04T22:02:54.518782Z","shell.execute_reply.started":"2024-06-04T22:02:54.509929Z","shell.execute_reply":"2024-06-04T22:02:54.517416Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Preprocess Data\n\n\t•\tFeatures Used: For all motors, the same set of features was used: positions, temperatures, and voltages of all six motors.\n\t•\tPreprocessing: Data was preprocessed to remove outliers and sequence variability. Features were standardized or scaled depending on the model:\n\t•\tLogistic Regression: StandardScaler\n\t•\tDecision Tree and Random Forest: RobustScaler","metadata":{}},{"cell_type":"code","source":"# Preprocess Data\ndef pre_processing(df: pd.DataFrame):\n    def remove_outliers(df: pd.DataFrame):\n        for col in df.columns:\n            if 'temperature' in col:\n                df[col] = df[col].where(df[col] <= 100, np.nan)\n                df[col] = df[col].where(df[col] >= 0, np.nan)\n                df[col] = df[col].ffill()\n            if 'voltage' in col:\n                df[col] = df[col].where(df[col] >= 6000, np.nan)\n                df[col] = df[col].where(df[col] <= 9000, np.nan)\n                df[col] = df[col].ffill()\n            if 'position' in col:\n                df[col] = df[col].where(df[col] >= 0, np.nan)\n                df[col] = df[col].where(df[col] <= 1000, np.nan)\n                df[col] = df[col].ffill()\n    def remove_seq_variability(df: pd.DataFrame):\n        for col in df.columns:\n            if 'temperature' in col or 'voltage' in col or 'position' in col:\n                df[col] = df[col] - df[col].iloc[0]\n    remove_outliers(df)\n    remove_seq_variability(df)\n    return df\n","metadata":{"execution":{"iopub.status.busy":"2024-06-04T22:02:54.521263Z","iopub.execute_input":"2024-06-04T22:02:54.521723Z","iopub.status.idle":"2024-06-04T22:02:54.536719Z","shell.execute_reply.started":"2024-06-04T22:02:54.521683Z","shell.execute_reply":"2024-06-04T22:02:54.535557Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Train and evaluate the Logistic Regression model\n\nFor motor 2 and 4. Uses a linear regression model. \n\n\t•\tFeatures: Positions, temperatures, and voltages of all six motors.\n\t•\tHyperparameter Tuning: Yes, hyperparameters were tuned using GridSearchCV with a parameter grid for the regularization strength C (values: [0.001, 0.01, 0.1, 1, 10, 100]).\n\t•\tImbalance Consideration: Yes, imbalance was considered by using class_weight='balanced' in the Logistic Regression model, which adjusts weights inversely proportional to class frequencies.","metadata":{}},{"cell_type":"code","source":"# Train and evaluate the Logistic Regression model\ndef train_logistic_regression(x_tr, y_tr):\n    steps = [\n        ('standardizer', StandardScaler()),\n        ('classifier', LogisticRegression(class_weight='balanced'))\n    ]\n    pipeline = Pipeline(steps)\n    param_grid = {\n        'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100]\n    }\n    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    grid_search = GridSearchCV(pipeline, param_grid, scoring='f1', cv=cv)\n    grid_search.fit(x_tr, y_tr)\n    return grid_search\n","metadata":{"execution":{"iopub.status.busy":"2024-06-04T22:02:54.537877Z","iopub.execute_input":"2024-06-04T22:02:54.538228Z","iopub.status.idle":"2024-06-04T22:02:54.554829Z","shell.execute_reply.started":"2024-06-04T22:02:54.538178Z","shell.execute_reply":"2024-06-04T22:02:54.553702Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Train and evaluate the Decision Tree model\n\nFor motor 3, this model utilizes of Decision Tree Classifier. \n\n\t•\tFeatures: Positions, temperatures, and voltages of all six motors.\n\t•\tHyperparameter Tuning: Yes, hyperparameters were tuned using GridSearchCV with a parameter grid for:\n\t•\tcriterion (values: ['gini', 'entropy'])\n\t•\tmax_depth (values: [None, 10, 20, 30])\n\t•\tmin_samples_split (values: [2, 5, 10])\n\t•\tmin_samples_leaf (values: [1, 2, 4])\n\t•\tImbalance Consideration: Not explicitly handled in the model setup, but decision trees can inherently handle some level of class imbalance.","metadata":{}},{"cell_type":"code","source":"# Train and evaluate the Decision Tree model\ndef train_decision_tree(x_tr, y_tr):\n    steps = [\n        ('scaler', RobustScaler()),  \n        ('classifier', DecisionTreeClassifier(random_state=42))    \n    ]\n    pipeline = Pipeline(steps)\n    param_grid = {\n        'classifier__criterion': ['gini', 'entropy'],\n        'classifier__max_depth': [None, 10, 20, 30],\n        'classifier__min_samples_split': [2, 5, 10],\n        'classifier__min_samples_leaf': [1, 2, 4]\n    }\n    grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, scoring='f1', cv=5)\n    grid_search.fit(x_tr, y_tr)\n    return grid_search\n","metadata":{"execution":{"iopub.status.busy":"2024-06-04T22:02:54.556540Z","iopub.execute_input":"2024-06-04T22:02:54.556919Z","iopub.status.idle":"2024-06-04T22:02:54.569867Z","shell.execute_reply.started":"2024-06-04T22:02:54.556889Z","shell.execute_reply":"2024-06-04T22:02:54.568636Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Train the Random Forest model\n\nUsed by motor 1,5 and 6. Random forest classifier, with hyperparameters tuned being the criterion, max_depth, min_samples_split and min_samples_leaf. The sliding window and sample step are both set at 1. \n\n\tFeatures: Positions, temperatures, and voltages of all six motors.\n\t•\tHyperparameter Tuning: No explicit hyperparameter tuning mentioned, but the model is initialized with n_estimators=100 and max_depth=10.\n\t•\tImbalance Consideration: Not explicitly handled in the model setup, but Random Forests are generally robust to class imbalance.\n","metadata":{}},{"cell_type":"code","source":"# Train the Random Forest model\ndef train_random_forest(x_tr, y_tr):\n    rf_pipeline = Pipeline([\n        ('scaler', RobustScaler()),\n        ('classifier', RandomForestClassifier(n_estimators=100, max_depth=10))\n    ])\n    rf_pipeline.fit(x_tr, y_tr)\n    return rf_pipeline","metadata":{"execution":{"iopub.status.busy":"2024-06-04T22:02:54.572472Z","iopub.execute_input":"2024-06-04T22:02:54.572865Z","iopub.status.idle":"2024-06-04T22:02:54.585923Z","shell.execute_reply.started":"2024-06-04T22:02:54.572834Z","shell.execute_reply":"2024-06-04T22:02:54.584764Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Data and submission\n\n\t•\tWindow Size and Sample Step: The sliding window approach was used with a window size of 1 and a sample step of 1 to prepare the training data.","metadata":{}},{"cell_type":"code","source":"# Load data\ndf_train, df_test = load_data()\n\n# Prepare the submission dataframe\nsubmission_path = '/kaggle/input/robot-predictive-maintenance/sample_submission.csv'\ndf_submission = pd.read_csv(submission_path)\ndf_submission.loc[:, ['data_motor_1_label', 'data_motor_2_label', 'data_motor_3_label', 'data_motor_4_label', 'data_motor_5_label', 'data_motor_6_label']] = -1\n\n# Process each motor separately with the specified models\nfor motor_idx in range(1, 7):\n    print(f\"Processing motor {motor_idx}...\")\n\n    # Specify the test conditions to include in the training\n    df_data_experiment = df_train[df_train['test_condition'].isin(['20240425_093699', '20240425_094425', '20240426_140055',\n                                                                   '20240503_164675', '20240503_165189', '20240503_163963',\n                                                                   '20240325_155003'])]\n\n    # Define the features\n    feature_list_all = [f'data_motor_{i}_position' for i in range(1, 7)] + \\\n                       [f'data_motor_{i}_temperature' for i in range(1, 7)] + \\\n                       [f'data_motor_{i}_voltage' for i in range(1, 7)]\n\n    # Extract the features\n    df_tr_x, df_tr_y = extract_selected_feature(df_data_experiment, feature_list_all, motor_idx, mdl_type='clf')\n\n    # Prepare the training data based on the defined sliding window\n    window_size = 1\n    sample_step = 1\n    X_train, y_train = prepare_sliding_window(df_x=df_tr_x, y=df_tr_y, window_size=window_size, sample_step=sample_step, mdl_type='clf')\n\n    # Choose the appropriate model for each motor\n    if motor_idx in [1, 5, 6]:\n        model = train_random_forest(X_train, y_train)\n    elif motor_idx in [2, 4]:\n        model = train_logistic_regression(X_train, y_train)\n    elif motor_idx == 3:\n        model = train_decision_tree(X_train, y_train)\n\n    # Prepare the testing dataset\n    df_test_x = df_test[feature_list_all + ['test_condition']]\n    X_test = prepare_sliding_window(df_x=df_test_x, window_size=window_size, sample_step=sample_step, mdl_type='clf')\n\n    # Make predictions on the test set\n    y_pred = model.predict(X_test.drop(columns=['test_condition'], errors='ignore'))\n\n    # Add predictions for the current motor to the submission dataframe\n    df_submission[f'data_motor_{motor_idx}_label'] = y_pred\n\n# Save the submission file\ndf_submission.to_csv('/kaggle/working/submission.csv', index=False)\nprint(\"Submission file saved.\")","metadata":{"execution":{"iopub.status.busy":"2024-06-04T22:02:54.587447Z","iopub.execute_input":"2024-06-04T22:02:54.587955Z","iopub.status.idle":"2024-06-04T22:05:04.738737Z","shell.execute_reply.started":"2024-06-04T22:02:54.587913Z","shell.execute_reply":"2024-06-04T22:05:04.737274Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Processing motor 1...\nProcessing motor 2...\nProcessing motor 3...\nProcessing motor 4...\nProcessing motor 5...\nProcessing motor 6...\nSubmission file saved.\n","output_type":"stream"}]}]}