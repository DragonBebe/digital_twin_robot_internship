{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem definition and task allocations.\n",
    "\n",
    "This project aims at detecting failure on the 6 motors of the robot ArmPi FPV from Hiwonder. To do so, we used differents AI model in order to dectect a potential abnormaly. \n",
    "As they are 6 motors on the robot, we decided to split the work : 3 persons worked on 2 specifics motors while the last person developped differents preprocessing algorithms that other could try to get better results.  \n",
    "The data available are position, temperature and voltage for each motors. For the training part, the label is also given. The goal is to predict the label of the 6 motors on the testing dataset given the 3 features of each motors.  \n",
    "The evaluation is based on F1 score. Indeed, the label class are unbalanced : they are way more class 0 than class with abnormlay. So accuracy isn't relevant : it's very easy to get very good results on accuracy by putting all 0 on the label. With the F1 score, the aim of the project is to have the best model on each of the 6 motors. \n",
    "\n",
    "Here is the table of the allocated work from group 2 :\n",
    "\n",
    "| Member | Task | \n",
    "| --- | --- |\n",
    "| Alix | Preprocessing |\n",
    "| Come | Motor 1&2|\n",
    "| Pierre | Motor 3&4 |\n",
    "| Max | Motor 5&6 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "import warnings\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "\n",
    "from util import read_all_test_data_from_path\n",
    "from utility import extract_selected_feature, prepare_sliding_window, run_cv_one_motor, FaultDetectReg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to design a Butterworth low-pass filter\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    nyquist = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "\n",
    "# Function to apply the Butterworth low-pass filter\n",
    "def lowpass_filter(data, cutoff_freq, sampling_freq, order=5):\n",
    "    b, a = butter_lowpass(cutoff_freq, sampling_freq, order=order)\n",
    "    filtered_data = filtfilt(b, a, data)\n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "# Set parameters for the low-pass filter\n",
    "cutoff_frequency = .5  # Adjust as needed\n",
    "sampling_frequency = 10  \n",
    "\n",
    "def customized_outlier_removal(df: pd.DataFrame):\n",
    "    ''' # Description\n",
    "    Remove outliers from the dataframe based on defined valid ranges. \n",
    "    Define a valid range of temperature and voltage. \n",
    "    Use ffil function to replace the invalid measurement with the previous value.\n",
    "    '''\n",
    "    df['position'] = df['position'].where(df['position'] <= 1000, np.nan)\n",
    "    df['position'] = df['position'].where(df['position'] >= 0, np.nan)\n",
    "    df['position'] = df['position'].ffill()\n",
    "    df['position'] = lowpass_filter(df['position'], cutoff_frequency, sampling_frequency)\n",
    "    df['position'] = df['position'].rolling(window=10, min_periods=1).mean()\n",
    "    df['position'] = df['position'].round()\n",
    "\n",
    "    df['temperature'] = df['temperature'].where(df['temperature'] <= 100, np.nan)\n",
    "    df['temperature'] = df['temperature'].where(df['temperature'] >= 0, np.nan)\n",
    "    df['temperature'] = df['temperature'].rolling(window=10, min_periods=1).mean()\n",
    "\n",
    "    # # Make sure that the difference between the current and previous temperature cannot be too large.\n",
    "    # # Define your threshold\n",
    "    # threshold = 10\n",
    "    # # Shift the 'temperature' column by one row to get the previous temperature\n",
    "    # prev_tmp = df['temperature'].shift(1)\n",
    "    # # Calculate the absolute difference between current and previous temperature\n",
    "    # temp_diff = np.abs(df['temperature'] - prev_tmp)\n",
    "    # # Set the temperature to NaN where the difference is larger than the threshold\n",
    "    # df.loc[temp_diff > threshold, 'temperature'] = np.nan\n",
    "    # df['temperature'] = df['temperature'].ffill()\n",
    "\n",
    "    df['voltage'] = df['voltage'].where(df['voltage'] >= 6000, np.nan)\n",
    "    df['voltage'] = df['voltage'].where(df['voltage'] <= 8000, np.nan)\n",
    "    df['voltage'] = df['voltage'].ffill()\n",
    "    df['voltage'] = lowpass_filter(df['voltage'], cutoff_frequency, sampling_frequency)\n",
    "    df['voltage'] = df['voltage'].rolling(window=5, min_periods=1).mean()\n",
    "\n",
    "def cal_diff(df: pd.DataFrame, n_int: int = 20):\n",
    "    ''' # Description\n",
    "    Calculate the difference between the current and previous n data point.\n",
    "    '''\n",
    "    # Tranform the features relative to the first data point.\n",
    "    df['temperature'] = df['temperature'] - df['temperature'].iloc[0]\n",
    "    df['voltage'] = df['voltage'] - df['voltage'].iloc[0]\n",
    "    df['position'] = df['position'] - df['position'].iloc[0]\n",
    "\n",
    "    # Calculate the difference between the current and previous n data point.\n",
    "    # df['temperature_diff'] = df['temperature'].diff(n_int)\n",
    "    # df['voltage_diff'] = df['voltage'].diff(n_int)\n",
    "    # df['position_diff'] = df['position'].diff(n_int)    \n",
    "\n",
    "def pre_processing(df: pd.DataFrame):\n",
    "    ''' ### Description\n",
    "    Preprocess the data:\n",
    "    - remove outliers\n",
    "    - add new features about the difference between the current and previous n data point.\n",
    "    '''\n",
    "    # Start processing.\n",
    "    customized_outlier_removal(df)\n",
    "    cal_diff(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data\n",
    "\n",
    "### Read the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings.\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Read the training dataset and preprocess\n",
    "base_dictionary = 'dataset/training_data/training_data/'\n",
    "df_train = read_all_test_data_from_path(base_dictionary, pre_processing, is_plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all the testing dataset with preprocessing\n",
    "base_dictionary = 'dataset/testing_data/'\n",
    "df_test = read_all_test_data_from_path(base_dictionary, pre_processing, is_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train files\n",
    "not_moving_train = ['20240105_164214', '20240105_165972', '20240320_152031', '20240320_155664','20240325_135213', '20240425_093699', '20240425_094425', '20240426_140055']\n",
    "pickup_and_place_train = ['20240105_165300', '20240321_122650', '20240325_152902','20240325_155003', '20240426_141190','20240503_163963']\n",
    "moving_one_motor_train = ['20240426_141532','20240426_141602','20240426_141726','20240426_141938','20240426_141980']\n",
    "turning_motor_6_train = ['20240503_164435','20240503_164675','20240503_165189' ]\n",
    "moving_motors_sequentially_train = ['20240320_153841']\n",
    "\n",
    "moving_motor_mixed_train = moving_one_motor_train + moving_motors_sequentially_train + turning_motor_6_train\n",
    "#Test files\n",
    "transfer_goods_test = [\"20240527_094865\",\"20240527_100759\",\"20240527_101627\"]\n",
    "not_moving_test = ['20240527_102436','20240527_102919','20240527_103311']\n",
    "moving_one_motor_test = ['20240527_103690','20240527_104247']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Violin plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "def violin_plt(label):\n",
    "    num_rows = 6  # Number of rows for the subplot grid\n",
    "\n",
    "    plt.figure(figsize=(20, num_rows * 5))  # Adjusting the figure size\n",
    "\n",
    "    for i in range(1, 7):\n",
    "        # Dynamically creating feature names based on the motor index\n",
    "        position_feature = f\"data_motor_{i}_position\"\n",
    "        temperature_feature = f\"data_motor_{i}_temperature\"\n",
    "        voltage_feature = f\"data_motor_{i}_voltage\"\n",
    "        label_feature = f\"data_motor_{label}_label\"\n",
    "\n",
    "        # Plotting position feature violin plot\n",
    "        plt.subplot(num_rows, 3, (i-1)*3 + 1)\n",
    "        sns.violinplot(y=position_feature, data=df_train, inner='quartile', hue=label_feature, split=True)\n",
    "        plt.title(f'Violin Plot of {position_feature}')\n",
    "        plt.ylabel(position_feature)\n",
    "\n",
    "        # Plotting temperature feature violin plot\n",
    "        plt.subplot(num_rows, 3, (i-1)*3 + 2)\n",
    "        sns.violinplot(y=temperature_feature, data=df_train, inner='quartile', hue=label_feature, split=True)\n",
    "        plt.title(f'Violin Plot of {temperature_feature}')\n",
    "        plt.ylabel(temperature_feature)\n",
    "\n",
    "        # Plotting voltage feature violin plot\n",
    "        plt.subplot(num_rows, 3, (i-1)*3 + 3)\n",
    "        sns.violinplot(y=voltage_feature, data=df_train, inner='quartile', hue=label_feature, split=True)\n",
    "        plt.title(f'Violin Plot of {voltage_feature}')\n",
    "        plt.ylabel(voltage_feature)\n",
    "\n",
    "    plt.tight_layout()  # Adjust subplots to fit in figure area.\n",
    "    plt.show()  # Display the figure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violin_plt(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violin_plt(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violin_plt(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violin_plt(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violin_plt(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violin_plt(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_plot = [col for col in df_train.columns if ('diff' not in col and 'time' not in col and 'test' not in col)]\n",
    "\n",
    "df_matrix = df_train.loc[:, col_to_plot]\n",
    "\n",
    "correlation_matrix = df_matrix.corr()\n",
    "\n",
    "correlation_matrix.columns = [col[5:] for col in correlation_matrix.columns]\n",
    "correlation_matrix.index = [index[5:] for index in correlation_matrix.index]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5, annot_kws={\"size\": 8})\n",
    "\n",
    "plt.title('Correlation Coefficient Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motor 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this motor, we chose 5 relevants features : \n",
    "- motor 1 temperature and position\n",
    "- motor 2 temperature\n",
    "- motor 3 temperature \n",
    "- motor 4 temperature  \n",
    "\n",
    "The best result we got on the testing dataset is a 0.758 f1 score with a random forest classificator with classical parameters (n_estiamtors = 100).  \n",
    "\n",
    "We prepared a window slide with parameters : \n",
    "- window_size = 100\n",
    "- sample = 2\n",
    "\n",
    "We trained the model on all the training dataset available \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "motor_idx = 1\n",
    "\n",
    "df_data_experiment = df_train[df_train['test_condition'].isin(not_moving_train + pickup_and_place_train+ moving_one_motor_train)]\n",
    "\n",
    "\n",
    "feature_list_motor1 = ['data_motor_1_temperature', 'data_motor_1_position', \n",
    "                       'data_motor_2_temperature',\n",
    "                        'data_motor_3_temperature',\n",
    "                        'data_motor_4_temperature'\n",
    "                       ]\n",
    "\n",
    "# Extract the features.\n",
    "df_tr_x, df_tr_y = extract_selected_feature(df_data_experiment, feature_list_motor1, motor_idx, mdl_type='clf')\n",
    "\n",
    "# Prepare the training data based on the defined sliding window.\n",
    "window_size = 100\n",
    "sample_step = 2\n",
    "X_train, y_train = prepare_sliding_window(df_x=df_tr_x, y=df_tr_y, window_size=window_size, sample_step=sample_step, mdl_type='clf')\n",
    "\n",
    "steps = [\n",
    "    ('standardizer', StandardScaler()), \n",
    "    ('mdl', RandomForestClassifier(class_weight='balanced') )  \n",
    "]\n",
    "pipeline = Pipeline(steps)\n",
    "param_grid = {\n",
    "    'mdl__n_estimators': [100]  # Inverse of regularization strength\n",
    "}\n",
    "\n",
    "model1 = GridSearchCV(estimator=pipeline, param_grid=param_grid, scoring='f1', cv=5)\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "feature_list_motor1 += ['test_condition']\n",
    "df_test_x = df_test[feature_list_motor1]\n",
    "# Augument the features in the same way as the training data.\n",
    "X_test = prepare_sliding_window(df_x=df_test_x, window_size=window_size, sample_step=sample_step, mdl_type='clf')\n",
    "\n",
    "y_pred_1 = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motor 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This motor was a bit harder to get good results and we only managed to get a 0.369 f1 score on the testing dataset.  \n",
    "To accomplish this, we used a LogisticRegression model with classic parametres (C=1).  \n",
    "We decided to put a window size of 100 with a sample step of 20. \n",
    "\n",
    "The features we selected thanks to the correlation matrix and with a few tries were as follow : \n",
    "- motor 1 temperature\n",
    "- motor 2 temperature and position\n",
    "- motor 3 temperature\n",
    "- motor 4 position\n",
    "\n",
    "We trained this model on the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motor_idx = 2\n",
    "\n",
    "df_data_experiment = df_train[df_train['test_condition'].isin(not_moving_train + pickup_and_place_train + moving_motor_mixed_train)]\n",
    "\n",
    "\n",
    "feature_list_motor2 = ['data_motor_1_temperature',\n",
    "                       'data_motor_4_position', \n",
    "                       'data_motor_2_temperature', 'data_motor_2_position',\n",
    "                       'data_motor_3_temperature'\n",
    "                       ]\n",
    "\n",
    "# Extract the features.\n",
    "df_tr_x, df_tr_y = extract_selected_feature(df_data_experiment, feature_list_motor2, motor_idx, mdl_type='clf')\n",
    "\n",
    "# Prepare the training data based on the defined sliding window.\n",
    "window_size = 100\n",
    "sample_step = 20\n",
    "X_train, y_train = prepare_sliding_window(df_x=df_tr_x, y=df_tr_y, window_size=window_size, sample_step=sample_step, mdl_type='clf')\n",
    "\n",
    "# Define the classification model.\n",
    "# Define the steps of the pipeline\n",
    "steps = [\n",
    "    ('standardizer', StandardScaler()),  # Step 1: StandardScaler\n",
    "    ('mdl', LogisticRegression(class_weight='balanced') )   # Step 2: Linear Regression\n",
    "]\n",
    "param_grid = {\n",
    "    'mdl__C': [1]  # Inverse of regularization strength\n",
    "}\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "model2 = GridSearchCV(estimator=pipeline, param_grid=param_grid, scoring='f1', cv=5)\n",
    "model2.fit(X_train, y_train)\n",
    "feature_list_motor2 += ['test_condition']\n",
    "\n",
    "df_test_x = df_test[feature_list_motor2]\n",
    "# Augument the features in the same way as the training data.\n",
    "X_test = prepare_sliding_window(df_x=df_test_x, window_size=window_size, sample_step=sample_step, mdl_type='clf')\n",
    "\n",
    "y_pred_2 = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motor 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see on the correlation matrix, the label of motor 3 seems to be correlated with none of the features. It was the most difficult motor to train.  \n",
    "\n",
    "The best result we got was a 0.268 f1-score on the testing dataset.  \n",
    "\n",
    "For that we trained a LogisticRegression (C=0.01) model on the whole dataset. We chose a window_size of 100 with a sample_step of 20.  \n",
    "The feature selection played a crucial role on the result. We tried a lot of differents combinations using the plot of the training dataset to see manually which features could be relevant to detect abnormaly. \n",
    "\n",
    "Surprisingly, none of the combinations we tried worked well and the best results was with using :\n",
    "- data motor 3 temperature and position\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motor_idx = 3\n",
    "\n",
    "df_data_experiment = df_train[df_train['test_condition'].isin(not_moving_train + pickup_and_place_train + moving_motor_mixed_train)]\n",
    "\n",
    "\n",
    "feature_list_motor3 = ['data_motor_3_position', 'data_motor_3_temperature']\n",
    "\n",
    "\n",
    "# Extract the features.\n",
    "df_tr_x, df_tr_y = extract_selected_feature(df_data_experiment, feature_list_motor3, motor_idx, mdl_type='clf')\n",
    "\n",
    "# Prepare the training data based on the defined sliding window.\n",
    "window_size = 100\n",
    "sample_step = 20\n",
    "X_train, y_train = prepare_sliding_window(df_x=df_tr_x, y=df_tr_y, window_size=window_size, sample_step=sample_step, mdl_type='clf')\n",
    "\n",
    "# Define the classification model.\n",
    "# Define the steps of the pipeline\n",
    "steps = [\n",
    "    ('standardizer', StandardScaler()),  # Step 1: StandardScaler\n",
    "    ('mdl', LogisticRegression(class_weight='balanced') )   # Step 2: Linear Regression\n",
    "]\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# # Define hyperparameters to search\n",
    "param_grid = {\n",
    "    'mdl__C': [0.01],  # Regularization parameter\n",
    "}\n",
    "\n",
    "# # Initialize GridSearchCV\n",
    "model3 = GridSearchCV(estimator=pipeline, param_grid=param_grid, scoring='f1', cv=5)\n",
    "model3.fit(X_train, y_train)\n",
    "# # Get the features.\n",
    "feature_list_motor3 += ['test_condition']\n",
    "\n",
    "df_test_x = df_test[feature_list_motor3]\n",
    "X_test = prepare_sliding_window(df_x=df_test_x, window_size=window_size, sample_step=sample_step, mdl_type='clf')\n",
    "\n",
    "y_pred_3 = model3.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motor 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this motor we used the 5 relevants features : \n",
    "- motor 1,3,4 and 6 temperature\n",
    "- motor 4 position\n",
    "\n",
    "Combined with a logistic regression (C = 1) model and a window_size of 100 / sample_step of 5 and a training on the not moving/pick_up_and_place dataset, the model got a 0.49 f1 score on the public testing dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motor_idx = 4\n",
    "\n",
    "df_data_experiment = df_train[df_train['test_condition'].isin(not_moving_train + pickup_and_place_train)]\n",
    "\n",
    "\n",
    "feature_list_motor4 = ['data_motor_1_temperature',\n",
    "                       'data_motor_3_temperature',\n",
    "                       'data_motor_4_temperature', 'data_motor_4_position',\n",
    "                       'data_motor_6_temperature']\n",
    "\n",
    "df_tr_x, df_tr_y = extract_selected_feature(df_data_experiment, feature_list_motor4, motor_idx, mdl_type='clf')\n",
    "\n",
    "# Prepare the training data based on the defined sliding window.\n",
    "window_size = 100\n",
    "sample_step = 5\n",
    "\n",
    "X_train, y_train = prepare_sliding_window(df_x=df_tr_x, y=df_tr_y, window_size=window_size, sample_step=sample_step, mdl_type='clf')\n",
    "\n",
    "# Define the classification model.\n",
    "# Define the steps of the pipeline\n",
    "\n",
    "steps = [\n",
    "    ('standardizer', StandardScaler()),  # Step 1: StandardScaler\n",
    "    ('mdl', LogisticRegression(class_weight='balanced') )   # Step 2: Linear Regression\n",
    "]\n",
    "\n",
    "# Create the pipeline\n",
    "model4 = Pipeline(steps)\n",
    "\n",
    "# # Define hyperparameters to search\n",
    "param_grid = {\n",
    "    'mdl__C': [1]  # Inverse of regularization strength\n",
    "}\n",
    "\n",
    "model4 = GridSearchCV(estimator=model4 , param_grid=param_grid, scoring='f1', cv=5)\n",
    "model4.fit(X_train, y_train)\n",
    "\n",
    "feature_list_motor4 += ['test_condition']\n",
    "df_test_x = df_test[feature_list_motor4]\n",
    "\n",
    "X_test = prepare_sliding_window(df_x=df_test_x, window_size=window_size, sample_step=sample_step, mdl_type='clf')\n",
    "y_pred_4 = model4.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motor 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.85 Rdf n =100, window=100/5\n",
    "\n",
    "As shown by the correlation matrix, this motor seems to have the same problem as the motor 3 : none of the features seems to be correlated to motor 5 label. \n",
    "\n",
    "But surprisingly, we got a 0.85 f1 score using a random forest classificator (n_estimators = 100) trained on the not moving + moving differents motor part from the training dataset.  \n",
    "We used :\n",
    "- motor 1,2, 5 and 6 temperature\n",
    "- motor 5 position\n",
    "with a window size of 100 and a sample step of 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motor_idx = 5\n",
    "\n",
    "df_data_experiment = df_train[df_train['test_condition'].isin(not_moving_train + moving_motor_mixed_train)]\n",
    "\n",
    "# Define the classification model.\n",
    "# Define the steps of the pipeline\n",
    "steps = [\n",
    "    ('standardizer', StandardScaler()),  # Step 1: StandardScaler\n",
    "    ('mdl', RandomForestClassifier(class_weight='balanced'))   \n",
    "]\n",
    "\n",
    "# Create the pipeline\n",
    "model5 = Pipeline(steps)\n",
    "\n",
    "# Define hyperparameters to search\n",
    "param_grid_5 = {\n",
    "    'mdl__n_estimators': [100]  # Inverse of regularization strength\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "model5 = GridSearchCV(estimator=model5, param_grid=param_grid_5, scoring='f1', cv=5)\n",
    "\n",
    "feature_list_motor5 = ['data_motor_1_temperature',\n",
    "                        'data_motor_2_temperature',\n",
    "                        'data_motor_5_temperature', 'data_motor_5_position',\n",
    "                        'data_motor_6_temperature'\n",
    "                    ]\n",
    "\n",
    "df_tr_x, df_tr_y = extract_selected_feature(df_data_experiment, feature_list_motor5, motor_idx = 5, mdl_type='clf')\n",
    "window_size = 100\n",
    "sample_step = 5\n",
    "X_train, y_train = prepare_sliding_window(df_x=df_tr_x, y=df_tr_y, window_size=window_size, sample_step=sample_step, mdl_type='clf')\n",
    "\n",
    "model5.fit(X_train, y_train)\n",
    "\n",
    "# Get the features.\n",
    "feature_list_motor5 = feature_list_motor5 + ['test_condition']\n",
    "\n",
    "df_test_x = df_test[feature_list_motor5]\n",
    "X_test = prepare_sliding_window(df_x=df_test_x, window_size=window_size, sample_step=sample_step, mdl_type='clf')\n",
    "\n",
    "\n",
    "y_pred_5 = model5.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motor 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, the motor 6 got a 0.337 f1-score on the testing dataset. \n",
    "To do that we trained on the whole training dataset, used a random forest classifier (n = 500) and a window, sample step of 100 and 10 respectively.  \n",
    "Here are the 4 features we selected :\n",
    "- motor 1 temperature\n",
    "- motor 4 position\n",
    "- motor 6 temperature\n",
    "- motor 6 position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motor_idx = 6\n",
    "\n",
    "df_data_experiment = df_train[df_train['test_condition'].isin(not_moving_train + pickup_and_place_train + moving_one_motor_train)]\n",
    "\n",
    "# Define the classification model.\n",
    "# Define the steps of the pipeline\n",
    "steps = [\n",
    "    ('standardizer', StandardScaler()),  # Step 1: StandardScaler\n",
    "    ('mdl', RandomForestClassifier(class_weight='balanced'))    \n",
    "]\n",
    "\n",
    "# Create the pipeline\n",
    "model6 = Pipeline(steps)\n",
    "\n",
    "# Define hyperparameters to search\n",
    "param_grid_6 = {\n",
    "    'mdl__n_estimators': [500]  # Inverse of regularization strength\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "# grid_search_6 = GridSearchCV(estimator=pipeline, param_grid=param_grid_6, scoring='f1', cv=5)\n",
    "feature_list_motor6 = ['data_motor_1_temperature',\n",
    "                    'data_motor_4_position',\n",
    "                    'data_motor_6_temperature', 'data_motor_6_position']\n",
    "\n",
    "df_tr_x, df_tr_y = extract_selected_feature(df_data_experiment, feature_list_motor6, motor_idx = 6, mdl_type='clf')\n",
    "window_size = 100\n",
    "sample_step = 10\n",
    "X_train, y_train = prepare_sliding_window(df_x=df_tr_x, y=df_tr_y, window_size=window_size, sample_step=sample_step, mdl_type='clf')\n",
    "\n",
    "\n",
    "model6.fit(X_train, y_train)\n",
    "\n",
    "# Get the features.\n",
    "feature_list_motor6 = feature_list_motor6 + ['test_condition']\n",
    "df_test_x = df_test[feature_list_motor6]\n",
    "X_test = prepare_sliding_window(df_x=df_test_x, window_size=window_size, sample_step=sample_step, mdl_type='clf')\n",
    "\n",
    "y_pred_6 = model6.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction.\n",
    "\n",
    "In this section, put the code of prediction here. In the end, please output a variable `y_pred_6`, containing the results of the prediction on motor 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the results as a submission file for the data challenge.\n",
    "\n",
    "In this section, we demo how to prepare the results as a submission file for the data challenge. First, we need to download the submission template `sample_submission.csv` from [kaggle](https://www.kaggle.com/competitions/robot-predictive-maintenance/data). As shown below, in this csv files, we just need to give our prediction on the six motors in the corresponding columns. You can find a demo below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the template.\n",
    "path = 'dataset/sample_solution.csv' # Change to your path.\n",
    "df_submission = pd.read_csv(path)\n",
    "\n",
    "# Initial all values with -1.\n",
    "df_submission.loc[:, ['data_motor_1_label', 'data_motor_2_label', 'data_motor_3_label', 'data_motor_4_label', 'data_motor_5_label', 'data_motor_6_label']] = -1\n",
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace each column with your prediction.\n",
    "# df_submission['data_motor_1_label'] = y_pred_1\n",
    "# df_submission['data_motor_2_label'] = y_pred_2\n",
    "df_submission['data_motor_3_label'] = y_pred_3\n",
    "# df_submission['data_motor_4_label'] = y_pred_4\n",
    "# df_submission['data_motor_5_label'] = y_pred_5\n",
    "# df_submission['data_motor_6_label'] = y_pred_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the submission csv.\n",
    "df_submission.to_csv('results/test_motor3.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
